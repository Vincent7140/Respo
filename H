
Cette partie vise à analyser la convergence du modèle au cours de l’entraînement, dans l’objectif d’évaluer s’il est possible de réduire le nombre d’itérations sans compromettre la qualité des résultats.
L’idée est d’observer l’évolution des différentes métriques (PSNR, SSIM, erreur d’altitude) pour identifier à quel moment elles atteignent un plateau, signe que le modèle a suffisamment appris. Une convergence rapide permettrait d’envisager un arrêt anticipé de l’entraînement, réduisant ainsi le temps de calcul sans perte significative de performance.

---



* **PSNR et SSIM** : montrent une stabilisation progressive ; le gain après un certain nombre d’itérations devient marginal.
* **Erreur d’altitude** : diminue fortement au début, puis tend vers une valeur stable, ce qui confirme la convergence du modèle.

La métrique MAE n’a pas été retenue ici. En effet, pour la calculer, une scène doit être générée selon une vue parfaitement verticale (nadir), permettant ensuite de produire un modèle numérique d’élévation (DEM). Chaque pixel de ce DEM est ensuite comparé à un DEM de référence obtenu par mesure LIDAR, servant de vérité terrain. Or, l’objectif de cette expérience est d’évaluer la capacité du modèle à reconstruire la scène depuis une vue intermédiaire (image 20), située entre trois vues proches angulairement. La scène générée n’étant pas nadirale, la MAE ne serait pas représentative dans ce cas précis.

Les résultats obtenus sont encourageants, avec des performances parfois meilleures que celles issues de l’entraînement avec 20 images précédemment utilisées. On observe cependant une reconstruction inégale selon les zones de l’image, ce qui souligne des limites dans la représentativité du modèle.

Cela met en évidence un compromis à trouver : avec un jeu de données restreint, concentré sur une zone réduite et des vues angulairement proches, il est possible d'obtenir une reconstruction partiellement fidèle. Mais pour améliorer la cohérence globale de la scène, une meilleure couverture angulaire ou spatiale pourrait être nécessaire.



Afin d'améliorer l'efficacité de l'entraînement des champs de radiance neuronaux, les auteurs proposent une stratégie d’échantillonnage de rayons guidée par les régions de pixels, fondée sur la variation locale des couleurs. L’idée est d’allouer davantage de rayons aux zones riches en informations (bords, textures, détails) et d’en réduire dans les zones homogènes. Concrètement, un score d’information est attribué à chaque pixel en calculant l’écart-type des couleurs dans un voisinage local. Ce score est ensuite normalisé pour former une distribution de probabilité $P_c'(u,v)$, utilisée à la place d’un échantillonnage uniforme. Cette méthode permet de concentrer les ressources de calcul sur les régions complexes de la scène, d’accélérer la convergence du réseau, et d’améliorer la qualité du rendu, tout en restant compatible avec les architectures NeRF existantes.

Si l’on se fie uniquement aux courbes du PSNR et du SSIM, le modèle semble atteindre un plateau de convergence bien avant les 100 000 itérations (notamment si l’on ne considère que le PSNR). Cependant, l’analyse de la MAE montre que le modèle continue à apprendre de manière significative jusqu’à environ 100 000 itérations, indiquant que cette durée est nécessaire pour une convergence complète du point de vue de la géométrie.
