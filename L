Représenter des scènes de manière à ce qu’elles soient les plus réalistes possibles constitue un défi important. L’objectif de ce stage est d’explorer de nouvelles approches basées sur les réseaux de neurones NeRFs, permettant de générer des représentations réalistes de scènes à partir d’un volume minimal de données. Dans un second temps, il s’agira d’évaluer et d’optimiser la représentativité des scènes obtenues.




Voici une version plus courte, tout en gardant l’essentiel :

---

### Introduction

La **reconstruction 3D** consiste à reproduire la structure d’une scène ou d’un objet à partir d’images ou de mesures, et elle est utilisée dans des domaines variés comme la cartographie, la réalité virtuelle ou la planification militaire. Les méthodes traditionnelles, telles que la photogrammétrie ou la stéréovision, donnent de bons résultats mais montrent leurs limites lorsque les conditions d’acquisition sont complexes : faible recouvrement d’images, variations d’éclairage ou absence de textures marquées.

Les **Neural Radiance Fields (NeRFs)**, introduits en 2020, apportent une approche différente : ils modélisent la scène comme une fonction continue reliant chaque point de l’espace à sa couleur et sa densité, ce qui permet de synthétiser des vues photoréalistes depuis n’importe quel point de vue. Ces modèles produisent des rendus très réalistes et capturent des détails fins, mais leur adaptation à l’imagerie satellite reste un défi à cause du faible nombre de vues disponibles, des variations lumineuses et des spécificités des caméras orbitales. Des variantes comme **Sat-NeRF** ou **SparseSat-NeRF** ont été développées pour répondre à ces contraintes tout en conservant la qualité de reconstruction.

---

Veux-tu que je te fasse aussi une **version orientée uniquement sur le contexte satellite**, pour coller encore plus à ton rapport ?

