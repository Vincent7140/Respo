def _weights_and_probs_from_rgb(image_hw3):
    """
    image_hw3: np.ndarray [H,W,3]
    return: w_map [H,W] in {1,3,5}, p_map [H,W] normalisée (somme=1)
    """
    norm = compute_color_variance_map(image_hw3, window_size=3)  # ta fonction
    w_map = np.where(norm >= 0.6, 5.0,
             np.where(norm >= 0.4, 3.0, 1.0)).astype(np.float32)
    s = float(w_map.sum())
    p_map = (w_map / s) if s > 0 else np.full(w_map.shape, 1.0 / w_map.size, dtype=np.float32)
    return w_map, p_map


def generate_train_rays(dataset, arg_dict):    
    use_view_dirs = arg_dict['model.ins.views']
    use_light_dirs = arg_dict['model.ins.light']
    el_adj = arg_dict['rend.unzoom']

    all_rays_o, all_rays_d, all_values = [], [], []
    if use_view_dirs:
        all_view_dirs = []
    if use_light_dirs:
        all_light_dirs = []

    # NEW: on accumule les probas par image pour fabriquer un index global pondéré
    probs_all_images = []  # liste de vecteurs [H*W] pour chaque image

    for view_i in range(len(dataset['train_imgs'])):
        img_tf_or_np = dataset['train_imgs'][view_i]
        img_np = img_tf_or_np.numpy() if isinstance(img_tf_or_np, tf.Tensor) else img_tf_or_np
        H, W, nbands = img_np.shape
        focals, poses = dataset['train_focals'], dataset['train_poses']

        if el_adj:
            el = dataset['train_view_dirs'][view_i][0,1]
            rays_o, rays_d = get_rays_zoom(H, W, focals[view_i], poses[view_i], 1/np.sin(el))
        else:
            rays_o, rays_d = get_rays_zoom(H, W, focals[view_i], poses[view_i], 1.0)

        rays_o = tf.reshape(rays_o, [H, W, 3])
        rays_d = tf.reshape(rays_d, [H, W, 3])
        values = dataset['train_imgs'][view_i]

        all_rays_o.append(rays_o)
        all_rays_d.append(rays_d)
        all_values.append(values)

        if use_view_dirs:
            all_view_dirs.append(tf.ones([H, W, 1]) @ dataset['train_view_dirs'][view_i])
        if use_light_dirs:
            all_light_dirs.append(tf.ones([H, W, 1]) @ dataset['train_light_dirs'][view_i])

        # NEW: proba par image (d’après tes seuils 0.4/0.6 -> poids 3/5)
        if nbands < 3:
            raise ValueError("Besoin d'au moins 3 canaux (RGB) pour la carte de variance de couleur.")
        rgb_img = img_np[..., :3]
        _, p_map = _weights_and_probs_from_rgb(rgb_img)  # [H,W]
        probs_all_images.append(p_map.reshape(-1))       # [H*W]

    # reshape/concat classiques
    all_values = tf.reshape(tf.convert_to_tensor(all_values), [-1, all_values[0].shape[-1]])
    all_rays_o = tf.reshape(tf.convert_to_tensor(all_rays_o), [-1, 3])
    all_rays_d = tf.reshape(tf.convert_to_tensor(all_rays_d), [-1, 3])

    all_train = {'rays_o': all_rays_o, 'rays_d': all_rays_d, 'values': all_values}
    if use_view_dirs:
        all_train['view_dirs'] = tf.reshape(tf.convert_to_tensor(all_view_dirs), [-1, 2])
    if use_light_dirs:
        all_train['light_dirs'] = tf.reshape(tf.convert_to_tensor(all_light_dirs), [-1, 2])

    # NEW: on fabrique UNE SEULE PERMUTATION pondérée (de taille N) pour tout le training
    probs_concat = np.concatenate(probs_all_images, axis=0)  # [N]
    probs_concat = probs_concat / probs_concat.sum()
    N = probs_concat.shape[0]
    # Index pondéré avec remplacement: les zones 5/3 apparaissent plus souvent.
    index_map = np.random.choice(N, size=N, replace=True, p=probs_concat).astype(np.int64)
    # on le stocke (Tensor) pour que get_ray_batch puisse l’utiliser sans changer ta boucle
    all_train['index_map'] = tf.convert_to_tensor(index_map)

    return all_train


def get_ray_batch(rays, start, end):
    """Retrieve subset of rays from start index to end index.
       Si 'index_map' est présent, on applique le mapping pondéré.
    """
    if 'index_map' in rays:
        # mapping d’indices pondéré pré-calculé
        imap = rays['index_map'].numpy() if isinstance(rays['index_map'], tf.Tensor) else rays['index_map']
        sel = imap[start:end]
        sub_rays = {}
        for k, v in iter(rays.items()):
            if k == 'index_map':   # on ne renvoie pas le mapping dans le batch
                continue
            if isinstance(v, tf.Tensor):
                sub_rays[k] = tf.gather(v, sel, axis=0)
            else:
                sub_rays[k] = v[sel, ...]
        return sub_rays
    else:
        # comportement d’origine
        sub_rays = {k: v[start:end, ...] for k, v in iter(rays.items())}
        return sub_rays
